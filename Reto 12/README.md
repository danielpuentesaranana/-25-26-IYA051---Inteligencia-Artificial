# Reto 12

Tema: ML: Clasificación: Perceptron

Descripción: Modelo perceptrón simple como fundamento de redes neuronales: convergencia, limitaciones y casos linealmente separables.
	
Para el ejercicio del perceptron (Ejercicio 01 de Redes Neuronales):
- ¿Qué representa un perceptrón dentro de una red neuronal y qué tipo de problemas puede resolver?
- ¿Cuál es el papel de los pesos  w1,w2,w3  en el perceptrón y cómo influyen en la salida final?
- Cambia los valores de los pesos w1,w2,w3 y analiza cómo varía el resultado de la salida y. ¿Qué interpretación tiene este cambio?
- Por qué se utiliza una función de activación (como tanh) y qué ventajas tiene frente a una función lineal
- Representa gráficamente la función tanh(s) y explica cómo se comporta para valores grandes y pequeños de s
- ¿Qué diferencias existen entre la función tanh, sigmoide y ReLU en cuanto a rango y comportamiento?
- Sustituye la función de activación tanh por una función sigmoide o ReLU y compara los resultados.
- ¿Cómo podría extenderse este modelo de una sola neurona a una red con varias capas (perceptrón multicapa, MLP)?
- Añade un término de sesgo (bias) al modelo y explica cómo afecta al cálculo de la salida.
- Modifica el código para que el perceptrón procese varios conjuntos de entradas (X) en forma de matriz y obtenga varios outputs a la vez.

Para el simulador de redes (http://playground.tensorflow.org/) comenta las pruebas realizadas para ajustar a diferentes entradas y cómo se comporta en cuanto a los datos.
